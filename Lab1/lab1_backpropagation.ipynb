{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab1 backpropagation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMFF+EJnxS5X0VwSpce68mC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chi-Ruei/Deep-learning-2021/blob/main/lab1_backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mINxGy-3BYNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f881eb4-139f-41af-e3e1-92ac9c24c9a7"
      },
      "source": [
        "import numpy as np \n",
        "#np.random.seed(0)\n",
        "\n",
        "def sigmoid (x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "#Input datasets\n",
        "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "expected_output = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "epochs = 10000\n",
        "lr = 0.1\n",
        "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\n",
        "\n",
        "#Random weights and bias initialization\n",
        "hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
        "hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n",
        "output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n",
        "output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
        "\n",
        "print(\"Initial hidden weights: \",end='')\n",
        "print(*hidden_weights)\n",
        "print(\"Initial hidden biases: \",end='')\n",
        "print(*hidden_bias)\n",
        "print(\"Initial output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Initial output biases: \",end='')\n",
        "print(*output_bias)\n",
        "\n",
        "\n",
        "#Training algorithm\n",
        "for _ in range(epochs):\n",
        "\t#Forward Propagation\n",
        "\thidden_layer_activation = np.dot(inputs,hidden_weights)\n",
        "\thidden_layer_activation += hidden_bias\n",
        "\thidden_layer_output = sigmoid(hidden_layer_activation)\n",
        "\n",
        "\toutput_layer_activation = np.dot(hidden_layer_output,output_weights)\n",
        "\toutput_layer_activation += output_bias\n",
        "\tpredicted_output = sigmoid(output_layer_activation)\n",
        "\n",
        "\t#Backpropagation\n",
        "\terror = expected_output - predicted_output\n",
        "\td_predicted_output = error * sigmoid_derivative(predicted_output)\n",
        "\t\n",
        "\terror_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
        "\td_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
        "\n",
        "\t#Updating Weights and Biases\n",
        "\toutput_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
        "\toutput_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
        "\thidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
        "\thidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
        "\n",
        "print(\"Final hidden weights: \",end='')\n",
        "print(*hidden_weights)\n",
        "print(\"Final hidden bias: \",end='')\n",
        "print(*hidden_bias)\n",
        "print(\"Final output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Final output bias: \",end='')\n",
        "print(*output_bias)\n",
        "\n",
        "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
        "print(*predicted_output)\n",
        "\n",
        "def generate_linear(n=100):\n",
        "    import numpy as np\n",
        "    pts = np.random.uniform(0,2,(n,2))\n",
        "    inputs = []\n",
        "    labels = []\n",
        "    for pt in pts :\n",
        "        inputs.append(pt[0, pt[1]])\n",
        "        distance = (pt[0]-pt[1])/1.414\n",
        "        if pt[0] > pt[1]:\n",
        "            labels.append(1)\n",
        "    return np.array(inputs), np.array(labels).reshape(n,1)\n",
        "\n",
        "def generate_XOR_easy():\n",
        "    import numpy as np\n",
        "    inputs = []\n",
        "    labels = []\n",
        "\n",
        "    for i in range(11):\n",
        "        inputs.append([0.1*i],0.1*i)\n",
        "        labels.append(0)\n",
        "\n",
        "        if 0.1*i == 0.5:\n",
        "           continue\n",
        "        \n",
        "        inputs.append([0.1*i , 1-0.1*i])\n",
        "        labels.append(1)\n",
        "    return np.array(inputs), np.array(labels).reshape(21,1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial hidden weights: [0.4758617  0.09006849] [0.16052708 0.57594922]\n",
            "Initial hidden biases: [0.55529449 0.017883  ]\n",
            "Initial output weights: [0.16285588] [0.32825574]\n",
            "Initial output biases: [0.37792423]\n",
            "Final hidden weights: [2.5379516  5.24387389] [2.51709861 5.08960342]\n",
            "Final hidden bias: [-3.75387165 -1.76677782]\n",
            "Final output weights: [-5.79266387] [5.61690319]\n",
            "Final output bias: [-2.47917851]\n",
            "\n",
            "Output from neural network after 10,000 epochs: [0.14288016] [0.83729619] [0.83810075] [0.19532991]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}